[{"title":"Dense Flow","date":"2018-07-01T08:00:42.000Z","path":"2018/07/01/DenseFlow/","text":"编译安装dense flow，用于提取光流特征，尝试安装opencv3.1后，安装dense flow失败，所以选择安装opencv2.4.13。源码地址 编译OpenCV2.4.1312345678# 下载源码wget https://github.com/opencv/opencv/archive/2.4.13.6.zip# 解压编译unzip 2.4.13.6.zip cd opencv-2.4.13.6/mkdir build &amp;&amp; cd buildcmake -D CMAKE_BUILD_TYPE=RELEASE -D WITH_TBB=ON -D WITH_V4L=ON ..make -j32 编译dense flow12345# 编译cd dense_flow/mkdir build &amp;&amp; cd buildOpenCV_DIR=.../your_opencv_path/build/ cmake .. -DCUDA_USE_STATIC_CUDA_RUNTIME=OFFmake -j 生成可执行文件：extract_cpu extract_gpu extract_warp_gpu 使用dense flow1./extract_gpu -f test.avi -x tmp/flow_x -y tmp/flow_y -i tmp/image -b 20 -t 1 -d 0 -s 1 -o dir test.avi: 输入视频文件 tmp: 输出RGB文件和光流文件 dir: 输出到文件夹。选择zip，会输出到zip文件 提取warp flow，使用以下命令 1./extract_warp_gpu -f test.avi -x tmp/flow_x -y tmp/flow_y -i tmp/image -b 20 -t 1 -d 0 -s 1 -o dir","tags":[{"name":"视频处理","slug":"视频处理","permalink":"https://geniuslight.github.io/tags/视频处理/"},{"name":"光流","slug":"光流","permalink":"https://geniuslight.github.io/tags/光流/"}]},{"title":"文献阅读整理1","date":"2018-06-29T08:00:42.000Z","path":"2018/06/29/ReadedPaperSummary1/","text":"6月21号，从南京匆匆赶到上海，开始了在平安科技的实习。实习的导师给了时序动作检测（Temporal Action Detection）这个任务。由于此前只是接触过detection的工作，所以开始疯狂阅读论文。阅读论文的思路是先对行为识别（Action Recognition）相关论文进行阅读，接下来阅读时序动作检测的相关论文。本文是对一周实习阅读的论文简单总结，论文按照发表的时间顺序排列。 任务简介 行为识别：输入一段分割好的视频，输出视频包含动作类别，类别通常是各类人的动作 时序动作检测：给定一段未分割的长视频，算法需要检测视频中的行为片段（action instance），包括其开始时间、结束时间以及类别。一段视频中可能包含一个或多个行为片段。 [1] Dense trajectories and motion boundary descriptors for action recognition 行为识别 发表时间：2013 使用密集采用的方式进行光流信息的提取，在多个空间尺度上进行密集采样，文中间隔5个pixel设置一个采样点，再除去大概率不是运动物体的采样点。在进行光流信息提取的时候，在连续帧的图像中，跟踪采样的点计算光流信息，文中是跟踪15帧。在提取特征的时候，使用HOG，HOF，MBH。使用Bag of Features进行每条轨迹对应特征的编码。最后使用的SVM进行分类。使用跟踪方式进行光流提取，对运动信息的描述更具有收敛性。其中使用MBH特征的描述可以一定程度上减小相机运动带来的影响。在使用非深度学习的方法前，效果应该是最好的，但是该方法计算速度比较慢。 [2] Action Recognition with Improved Trajectories 行为识别 发表时间：2013 在[1]工作上进行改进，也就是大名鼎鼎的iDT算法。基本的框架和[1]一致，改进之处主要是更好地对相机运动进行估计，消除相机运动带来的影响（移动，缩放等）。估计两帧图像的变换矩阵，就是相机运动的方式，使用多个采样点来估计矩阵。采用了两种方法来获得匹配点对，分别为SURF特征以及光流特征。 作者进一步消除人的运动对于变换矩阵估计的影响。先用检测算法检测到人的位置，去除处于人位置上的特征点。对特征进行编码时，使用效果更好的Fisher Vector编码 。iDT算法在后续的基于深度学习的时序动作检测研究中，也会被用于提取时序的特征。 [3] Two-Stream Convolutional Networks for Action Recognition in Videos 行为识别 发表时间：2014 网络的结构如下所示。把空间和时间的信息分开来，分别提取特征。 在对空间特征进行提取的时候，使用单帧的RGB图像作为输入，可以使用预训练的模型。在对时间特征进行提取的时候，使用多帧的光流作为输入。最后将提取的特征进行融合，进行分类。对光流进行提取时，实验了一般方法和对特征点进行跟踪提取的方式。在对特征进行融合时，使用了平均和堆叠的方法。在进行光流训练时，由于数据量不够，使用了多任务训练的方法。 np1ZG.png [4] Learning Spatiotemporal Features with 3D Convolutional Networks 行为识别 发表时间：2015 关于行为识别的工作。使用一个网络结构提取时间和空间的特征进行分类，文章主要是实验设计了一个网络结构。提出3 × 3 × 3 卷积核和3维池化的方式，使得对时间的信息提取更好，得到更好的分类性能。 [5] Temporal Segment Networks: Towards Good Practices for Deep Action Recognition 行为识别 发表时间：2016 针对长时间序列的行为识别，使用稀疏采样的策略。并且使用一系列策略来训练高效的网络。对于一个输入的视频，将被分成K个segments，从每个segment中随机地选择一个short snippet。将选择的snippets通过two-stream卷积神经网络得到不同snippets的class scores，最后将它们融合。 使用输入的有RGB images、stacked optical flow field、RGB difference和warped optical flow field。 在预防过拟合策略上，使用预训练、freeze BN层的均值和方差（除去第一层外）和数据扩充。 [6] Temporal Action Detection with Structured Segment Network 时序动作检测 发表时间：2017 使用的proposal+分类的思路，文章提出了一种时序动作提名算法TAG，以及后续的分类/边界回归网络 SSN。SSN将proposal的区域扩展，形成了开始-中间-结束区间的三段式设计，SSN的结构如下。在中间，使用空间池化，更好获取特征。三段区域的特征再进行拼接，获得更好的全局特征。并且意思是中间段的特征会更加明显。 npkna.png [7] Single Shot Temporal Action Detection 时序动作检测 发表时间：2017 上交林天威学长的工作，本人有简单介绍：链接。类似SSD和YOLO2的做法，使用anchors来进行候选区域。下图细致展示了本文方法的几个主要流程。即(1)特征提取；(2)SSAD模型； (3)后处理（训练或测试）。使用多种方法进行特征提取，然后拼接在一起。在获得长度为T的特征序列后，就可以将其用作SSAD模型的输入。SSAD模型是一个全部由时序卷积（一维卷积）构成的网络。主要包括三种卷积层：base, anchor, prediction layer。 base layers 的作用为缩短特征序列的长度，并增大特征序列中每个位置的感受野。 anchor layer 输出的特征序列中的每个位置都被关联了多个尺度的anchor instances（一个instance代表视频中动作发生的那一段时间，可以理解为一个一维的default box）。之后，再通过prediction layer，来获取每个anchor instances所对应的 坐标偏移量，重叠置信度，以及类别分类结果。","tags":[{"name":"视频处理","slug":"视频处理","permalink":"https://geniuslight.github.io/tags/视频处理/"},{"name":"深度学习","slug":"深度学习","permalink":"https://geniuslight.github.io/tags/深度学习/"}]},{"title":"在南京瞎逛系列1","date":"2018-05-26T08:00:42.000Z","path":"2018/05/26/InNanjingSeries1/","text":"一场从南京江北出发的旅行马上就要毕业，感觉离开南京去了上海很难有机会在这座城市安静的呆上几天，这时又想到大学四年对于南京各个地方的记忆是那么的匮乏，感觉到一阵遗憾，所以趁着大四这段悠闲的时光，开始自己的南京瞎逛之旅。 游玩的路线是：中山码头——浦口火车站——南京工业大学—— 绿博园 22_AZp.png 大致的想法是先坐车跑到长江边上，去看看曾经的中山码头，感受一下轮渡，坐轮渡到江北后，再顺路逛回学校。因为事先没有好好规划，而且是一个人出去瞎逛，所以感觉十分轻松，没有要完成任务的感觉，自己也可以探索一些觉得有意思的地方，一路上想停下来了，就走走看看。 中山码头和浦口火车站中山码头的风格和具有民国的风格，作为曾经一种重要的交通工具，他的出现据说可以追溯到1910年。在1925年比较重要的事情是中山先生的遗体是通过铁路到浦口火车站后，经过轮渡从浦口码头到中山码头进入南京城，因此码头的名字被叫做中山码头，也是对伟人的一种纪念。在长江大桥开通以前，中山码头是很重要的枢纽，如今也发挥着它的作用，去坐轮渡的时候，轮船的一楼全是小电驴，二楼也有很多人。 22v_JR.md.jpg 相比中山码头，江对面的浦口码头略显破败。在江的南北，就仿佛是两个世界，江南可见高楼林立，江北是破败的建筑，只是可见昔日的风光。街上的行人寥寥无几，还看到步履蹒跚的老人在巷子中行走，让我觉得突然一江之隔便是城乡之隔，这种巨大的落差十分震撼。 长江南岸 22h_Xd.md.jpg 长江北岸 22_WTS.md.jpg 从浦口码头下来，没走几步就看到了浦口火车站，现在的浦口火车站（也叫南京北站）已经不再发挥它的功能，成为了被保护的文物，火车站建筑的屋顶上还长草了，让我怀疑此处是不是被遗忘了的文物。在火车站的背后不远处便是铁路，一两节车厢还停止在铁轨上，放佛在述说昔日此地的繁华。想走近去看的时候，别人拒绝了，所以也就只能远远的观看了一番。 火车站建筑 破败火车站建筑后方的猫（十分怕生） 火车进站处 22b_U9.md.jpg 远远看着火车 22d_Jh.md.jpg 南京工业大学在浦口火车站瞎逛了半个小时后，途径浦口公园后很快就找到了公交车站，于是坐上了去南京绿博园的公交车。在旅途中，发现会途径南京工业大学，想起自己还有学妹在此地念书，于是果断下车，去南京工业大学江浦校区一逛。 南京工业大学给我的感觉像是一座巨大的公园，学校的教学楼实验室就置身于这美丽的仙境。南京工业大学处于山中，所以学校内有十分陡峭的山坡，学校内便是禁止骑车，全程靠走，学校又大，真的很累。听学妹介绍了一处处进景点，在看到一个很大的湖泊后，学妹带我去看了更大的湖泊，每个湖泊我都觉得比南大的漂亮许多（我觉得是因为他们学校有园林专业的原因，虽然学妹没有认同我233）。在学校中甚至有孔雀，还有露天的音乐广场，每一处都是十分美丽的景色，看的我都忘记了拍照。不过在经过校史博物馆时，还是拍下了奇葩的建筑。下细上粗的造型，还十分庄严地配上了工大的校徽，但是给我一种说不出的奇怪感觉，这种奇特的建筑，真的是第一次见。 2q2m_A.md.jpg 和学妹一起在食堂吃了午饭，听学妹谈及大学的生活，不得不感慨自己的生活真的是太单调了。在外靠朋友，十分感谢学妹招待！！！ 南京绿博园绿博园就是一个公园了，一个十分巨大的公园，总共面积有2千多亩。满园大都是植物，可惜很多不认识……一些建筑也有西方的风格，但是一些十分有名的建筑由于时间原因（时间不够）、计划原因（在园内瞎逛）和体力原因（走的很累，后来发现能骑车），没有能够去一一参观。 整个园区规划十分清晰，但是等我去的时候，发现荷兰园的郁金香凋谢了，花海的花开的不是很盛，总之没有看到十分美丽的景色。不过走在其中，仿佛离开了南京这座城市，园内树木郁郁葱葱，鸟儿叽叽喳喳，真正感受到了大自然存在。在南京有这种地方的存在，实在是南京人的福分。放几张照片，虽然拍的不好，但是感受一下吧。 22_TMn.md.jpg 22_Xe_E.md.jpg 总结一个人出去逛的感觉就是很爽，没有丝毫的负担，没有计划感受到了很多新奇，有了更大的自由度，但是也错过了停留地方的一些景点。有时间了继续逛南京，希望在毕业前能够在脑海中勾勒出一个生动的南京的存在。","tags":[{"name":"随笔","slug":"随笔","permalink":"https://geniuslight.github.io/tags/随笔/"},{"name":"游玩","slug":"游玩","permalink":"https://geniuslight.github.io/tags/游玩/"}]},{"title":"IICEE526服务器管理","date":"2018-04-04T08:00:42.000Z","path":"2018/04/04/IICEE526Server/","text":"服务器的硬件配置和使用注意 GPU：GTX1080TI AERO 11G（4块） CPU：Intel E5-2678 V3 （2块） 内存：DDR4 RECC 共64G 硬盘：机械硬盘 4T（2块）SSD 500G 使用时候个人觉得要注意： 先观察GPU有没有人在使用，如果贸然使用，可能会杀死别人在跑的程序 安装软件，注意选择版本，比如tensorfolw不同版本对cuda和cudnn的版本要求不一样，一般会根据cuda来安装相应版本的深度学习框架 谨慎使用root权限，可以的话，使用普通用户权限 能不重启服务器，就不要重启，重启是使用who和ps aux 指令，查看最近用户登入时间和程序运行 python使用的时候，使用virtualenv，anaconda等工具，管理好包的安装 服务器管理用户管理如果需要使用，找root管理员开账号，相关常用的命令有 1234#添加用户，adduser 你的用户名#切换用户su 需要切换的用户名 磁盘管理查看磁盘空间命令如下 1df -h / 目录挂载的是SSD，所以只有500G内存。/home/sdb，/home/sdc 分别挂载的是2块4T硬盘 请选择到/home/sdb或者/home/sbc下创建自己的目录，并且在自己创建目录下存放数据，不要默认在/home/你的用户名 文件下操作，这样很快占满硬盘空间。如果需要方便，可以创建软链接，指向某个位置。 综上，比如说开启新用户（sample）的流程为 1234567#添加用户，会需要你设置密码，密码设置好后，回车就行adduser sample#到4T硬盘挂载目录下创建你的目录mkdir /home/sdb/sample_space#创建软连接到用户目录下ln -s /home/sdb/sample_space /home/sample#可以方便地 在/home/sample/sample_space访问 服务器连接ssh连接使用ssh连接，没有界面，但是会十分流畅 在windows上，可以使用软件进行管理连接，比如说xshell 在linux上，可以在终端之间输入：ssh 用户名@IP地址 在实验室网络内连接IP:192.168.1.102:22（数据传输很快） 在实验室网络外连接IP:202.120.37.2:5900（数据传输较慢） vnc连接使用vnc连接，可以使用界面（推荐使用xface4桌面） 服务器的vnc安装过程(读一下有助于更好使用！) widows和linux都可以下载客户端 。使用十分简单，但是在网络不是很畅通的时候，会比较卡。 anaconda3中有dbus-launch，会和vnc桌面发生冲突，可能导致终端无法打开，所以不要把anacoda3的path添加到环境变量中。 启动后，在各个桌面下可以使用同样ID和密码进行连接，下载客户端即可连接。 在实验室网络内连接时，IP为：192.168.1.102 在实验室网络外连接时，IP为：202.120.37.2 GPU使用GPU使用情况查看12#输入下面命令nvidia-smi 5FyL7z.md.png ]图片上方是4块GPU信息，编号为0、1、2、3- Volatile GPU-UTIL ：表示单块GPU使用效率，数值越大说明代码写的很高效- Process GPU是占用的GPU和相关进程如果GPU 0 有人使用了5G的显存，然而你想用10G，程序会出现报错## GPU使用指定1234567#比如原来执行python指令为，会使用所用的GPUpython test.py#修改后，假如使用第2、3块GPUCUDA_VISIBLE_DEVICES=1,2 python test.py#以上是在命令行运行时候设置，也可以再python代码中设置，在代码开头添加import osos.environ['CUDA_VISIBLE_DEVICES']='2，3'","tags":[{"name":"Linux","slug":"Linux","permalink":"https://geniuslight.github.io/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"https://geniuslight.github.io/tags/运维/"}]},{"title":"vncserver多用户启动","date":"2018-03-12T20:01:51.000Z","path":"2018/03/13/VncserverMultiUserStart/","text":"管理多个用户使用su指令（py脚本中使用）[root@www ~]# su [-lm][-c 指令] [username]选项与参数： - ：单纯使用 - 如‘ su - ’代表使用 login-shell 的变数档案读取方式来登入系统； 若使用者名称没有加上去，则代表切换为 root 的身份。-l ：与 - 类似，但后面需要加欲切换的使用者帐号！也是 login-shell 的方式。-m ：-m 与 -p 是一样的，表示‘使用目前的环境设定，而不读取新使用者的设定档’-c ：仅进行一次指令，所以 -c 后面可以加上指令喔！ 使用脚本管理多用户在/etc/文件下，新建vncserver文件夹，在vncserver文件夹下新增两个文件startvnc.py和startvnc.sh,两个文件内容分别为： startvnc.py： 123456789101112131415161718192021222324import sysimport os user_list=[\"wst\",\"nju_zhao\",\"xuxudong\",\"visitor\",\"shaoyidi\"] #不同用户i = 1 depth = \"16\" geometry_list = [\"1920x1080\", \"1920x1080\", \"1920x1080\", \"1920x1080\", \"2880x1800\"] #不同分辨率 name = \"vncserver\" user_config = zip(user_list, geometry_list)#构建不同用户和对应端口的指令for name, geometry in user_config: options = \"-name %s -depth %s -geometry %s :%d\" % (name, depth, geometry, i) print(options) i = i + 1 cmd = \"su %s -c '/usr/bin/vncserver %s'\" % (name, options) print(cmd) os.system(cmd) startvnc.sh: 123#!/bin/bash python /etc/vncserver/startvnc.py exit 0 添加开机执行给文件执行权限 1chmod + x startvnc.sh 将命令添加到/etc/rc.local的末尾，以执行文件，添加内容为 1sh /etc/vncserver/startvnc.sh 参考：Ubuntu 14.04 解决VNC server 自启动 参考：鸟哥的linux私房菜","tags":[{"name":"Linux","slug":"Linux","permalink":"https://geniuslight.github.io/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"https://geniuslight.github.io/tags/运维/"}]},{"title":"nova服务器管理","date":"2018-03-08T17:00:42.000Z","path":"2018/03/09/NovaServer/","text":"服务器的硬件配置和使用注意 GPU：GTX1080TI AERO 11G 2块 CPU：Intel E5-2650V4 内存：DDR4 RECC 2133 16G 硬盘：机械硬盘 4T 使用时候个人觉得要注意： 先观察GPU有没有人在使用，如果贸然使用，可能会杀死别人在跑的程序 安装软件，注意选择版本，比如tensorfolw不同版本对cuda和cudnn的版本要求不一样，一般会根据cuda来安装相应版本的深度学习框架 谨慎使用root权限，可以的话，使用普通用户权限 能不重启服务器，就不要重启，重启是使用who和ps aux 指令，查看最近用户登入时间和程序运行 python使用的时候，使用virtualenv，anaconda等工具，管理好包的安装 服务器连接ssh连接使用ssh连接，没有界面，但是会十分流畅 在windows上，可以使用软件进行管理连接，比如说xshell 在linux上，可以在终端之间输入：ssh 用户名@IP地址 使用的都是默认端口22，如果你需要，可以自己改端口 vnc连接使用vnc连接，可以使用界面 服务器的vnc安装过程(读一下有助于更好使用！) widows和linux都可以下载客户端 。使用十分简单，但是在网络不是很畅通的时候，会比较卡。 anaconda3中有dbus-launch，会和vnc桌面发生冲突，可能导致终端无法打开，所以不要把anacoda3的path添加到环境变量中。 管理vnc账号和自动登陆参看教程： vncserver多用户启动 在外网使用服务器参看教程：用frp打开一扇通向内网的门","tags":[{"name":"Linux","slug":"Linux","permalink":"https://geniuslight.github.io/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"https://geniuslight.github.io/tags/运维/"}]},{"title":"opencv-python实现图像色彩空间转换","date":"2018-02-01T07:18:41.000Z","path":"2018/02/01/opencv-pythonConvertColor/","text":"opencv自带RGB ↔ GRAYTransformations within RGB space like adding/removing the alpha channel, reversing the channel order, conversion to/from 16-bit RGB color (R5:G6:B5 or R5:G5:B5), as well as conversion to/from grayscale using: RGB[A] to Gray:Y←0.299⋅R+0.587⋅G+0.114⋅Band Gray to RGB[A]:R←Y,G←Y,B←Y,A←max(ChannelRange)The conversion from a RGB image to gray is done with: 11 cvtColor(src, bwsrc, cv::COLOR_RGB2GRAY); 转化算法详细 Changing Color-spaceThere are more than 150 color-space conversion methods available in OpenCV. But we will look into only two which are most widely used ones, BGR↔ Gray and BGR ↔ HSV. For color conversion, we use the function cv2.cvtColor(input_image, flag) where flag determines the type of conversion. For BGR –&gt;Gray conversion we use the flags cv2.COLOR_BGR2GRAY. Similarly for BGR –&gt; HSV, we use the flag cv2.COLOR_BGR2HSV. To get other flags, just run following commands in your Python terminal : 123import cv2flags = [i for i in dir(cv2) if i.startswith('COLOR_')]print flags Note For HSV, Hue range is [0,179], Saturation range is [0,255] and Value range is [0,255]. Different softwares use different scales. So if you are comparing OpenCV values with them, you need to normalize these ranges. ps. 此处使用的是cv2,cv不含COLOR_BGR2GRAY，但是有类似方法 Object Tracking(示例)Now we know how to convert BGR image to HSV, we can use this to extract a colored object. In HSV, it is more easier to represent a color than RGB color-space. In our application, we will try to extract a blue colored object. So here is the method: Take each frame of the video Convert from BGR to HSV color-space We threshold the HSV image for a range of blue color Now extract the blue object alone, we can do whatever on that image we want. Below is the code which are commented in detail : 123456789101112131415161718192021222324252627282930import cv2import numpy as npcap = cv2.VideoCapture(0)while(1): # Take each frame _, frame = cap.read() # Convert BGR to HSV hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # define range of blue color in HSV lower_blue = np.array([110,50,50]) upper_blue = np.array([130,255,255]) # Threshold the HSV image to get only blue colors mask = cv2.inRange(hsv, lower_blue, upper_blue) # Bitwise-AND mask and original image res = cv2.bitwise_and(frame,frame, mask= mask) cv2.imshow('frame',frame) cv2.imshow('mask',mask) cv2.imshow('res',res) k = cv2.waitKey(5) &amp; 0xFF if k == 27: breakcv2.destroyAllWindows() Below image shows tracking of the blue object: [转载]使用伪色彩映射的方法进行转化转载自： http://blog.csdn.net/yhl_leo/article/details/52163236 在实验过程中，经常见到别人实验中展现的酷炫多彩的分割图或者概率图的伪彩色图，如随意生成一张概率图： gray 大家都知道人眼对灰度的识别能力远差于彩色的识别能力，这灰蒙蒙的是什么鬼… 可以使用OpenCV的applyColorMap对图像进行颜色渲染，生成伪彩色图像： C++ 123456789#include &lt;opencv2/contrib/contrib.hpp&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;using namespace cv; Mat im_gray = imread(\"pluto.jpg\", IMREAD_GRAYSCALE);Mat im_color;applyColorMap(im_gray, im_color, COLORMAP_HSV);123456789 Python 1234import cv2 im_gray = cv2.imread(\"pluto.jpg\", cv2.IMREAD_GRAYSCALE)im_color = cv2.applyColorMap(im_gray, cv2.COLORMAP_HSV)1234 color 可以看出，伪彩色图中展现的信息更多。 OpenCV定义了12种COLORMAP_*.可以产生这样的 Value Name Scale 0 COLORMAP_AUTUMN colorscale_autumn 1 COLORMAP_BONE colorscale_bone 2 COLORMAP_JET colorscale_jet 3 COLORMAP_WINTER colorscale_winter 4 COLORMAP_RAINBOW colorscale_rainbow 5 COLORMAP_OCEAN colorscale_ocean 6 COLORMAP_SUMMER colorscale_summer 7 COLORMAP_SPRING colorscale_spring 8 COLORMAP_COOL colorscale_cool 9 COLORMAP_HSV colorscale_hsv 10 COLORMAP_PINK colorscale_pink 11 COLORMAP_HOT colorscale_hot 此外，还可以自己定义一个颜色查询图，将灰度值0-255分别映射到对应的256种颜色上，在OpenCV中，可以创建一个256x1的彩色图，存储着预先定义的256种彩色值，通过使用LUT函数将彩色值映射到灰度图像上： C++ 1234Mat im_color;// NOTE : im_gray is 3-channel image with identical // red, green, blue channels. LUT(im_gray, lut, im_color);1234 Python 123# NOTE : im_gray is 3-channel image with identical# red, green, blue channels. im_color = cv2.LUT(im_gray, lut)123 其中，对于多通道的输入，参数lut的通道数可以为1或者与输入图像的通道数相同。 附上一张OpenCV提供的12种样式表的示例图： img 参考： Changing Colorspaces Color conversions OpenCV docs: applyColorMap OpenCV docs: LUT Learn OpenCV: applyColorMap for pseudocoloring in OpenCV","tags":[{"name":"图像处理","slug":"图像处理","permalink":"https://geniuslight.github.io/tags/图像处理/"},{"name":"opencv","slug":"opencv","permalink":"https://geniuslight.github.io/tags/opencv/"}]},{"title":"opencv-python读取和写入tiff图像","date":"2018-02-01T07:04:10.000Z","path":"2018/02/01/opencv-pythonReadWriteTiff/","text":"Tiff图像介绍标签图像文件格式（Tagged Image File Format，简写为TIFF）是一种灵活的位图格式，主要用来存储包括照片和艺术图在内的图像。 TIFF是一个灵活适应性强的文件格式。通过在文件标头中使用“标签”，它能够在一个文件中处理多幅图像和数据。标签能够标明图像的如图像大小这样的基本几何尺寸，或者定义图像数据是如何排列的，或者是否使用了各种各样的图像压缩选项。例如，TIFF可以包含JPEG和进程长度编码压缩的图像。TIFF文件也可以包含基于矢量的裁剪区域（剪切或者构成主体图像的轮廓）。使用无损格式存储图像的能力使TIFF文件成为图像存档的有效方法。与JPEG不同，TIFF文件可以编辑然后重新存储而不会有压缩损失。其它的一些TIFF文件选项包括多层或者多页。 opencv读取图像12import cv2cv2.imread(\"filename\",flags) 对于cv2，imread的关于通道数和位深的flags有五种选择： IMREAD_UNCHANGED = -1#不进行转化，比如保存为了16位的图片，读取出来仍然为16位。IMREAD_GRAYSCALE = 0#进行转化为灰度图，比如保存为了16位的图片，读取出来为8位，类型为CV_8UC1。IMREAD_COLOR = 1#进行转化为RGB三通道图像，图像深度转为8位IMREAD_ANYDEPTH = 2#保持图像深度不变，进行转化为灰度图。IMREAD_ANYCOLOR = 4#若图像通道数小于等于3，则保持原通道数不变；若通道数大于3则只取取前三个通道。图像深度转为8位 示例不转化读取，图像通道和数据类型都不会变 不转化读取，tiff图像保存为其他图像，则数据类型可能改变 不转化读取，tiff保持为tiff图像，则不发生改变 12345678910111213141516171819202122232425import cv2import sysimport osimg_path = 's1a-iw-grd-vh-20150823t221233-20150823t221258-007396-00a2ca-002'img_list = os.listdir(img_path)for img_name in img_list: if '.tiff' in img_name: #保持不变读取 img = cv2.imread(os.path.join(img_path, img_name), -1) print('不进行转化读取') print(img.dtype) print(img.shape) #默认读取方式 img = cv2.imread(os.path.join(img_path, img_name)) print('进行转换读取') print(img.dtype) print(img.shape) if '.jpg' in img_name: #上述文件保存为jpg后读取 img = cv2.imread(os.path.join(img_path, img_name), -1) print('不进行转化读取后保存为jpg，不进行转化读取（此处保存完成，直接读取）') print(img.dtype) print(img.shape) 结果如下： 123456789不进行转化读取后保存为jpg，不进行转化读取（此处保存完成，直接读取）uint8(448, 448)不进行转化读取uint16(448, 448)进行转换读取uint8(448, 448, 3)","tags":[{"name":"图像处理","slug":"图像处理","permalink":"https://geniuslight.github.io/tags/图像处理/"},{"name":"opencv","slug":"opencv","permalink":"https://geniuslight.github.io/tags/opencv/"}]},{"title":"[转载]用frp打开一扇通向内网的门","date":"2018-01-30T08:40:30.000Z","path":"2018/01/30/FrpUse/","text":"如何在广域网访问校园内网里的服务呢？我们需要一个叫做frp工具为我们进行反向代理。那么反向代理是如何工作的呢？首先，我们需要一个处在公网之中有公网IP的主机，装好frp服务的内网服务器会每隔一段时间就向远程主机发送一个数据包，这样在路由器中就始终会有一个端口分配给这个内网服务器，外网主机可以随时通过这条连接向内网的服务器发送数据。当我们在广域网访问内网服务器的时候，我们的请求会先发送给我们处在外网的主机，当这台主机接收到了数据，就会转发这个数据包给内网的服务器，服务器中运行的程序接收到了这个数据包，又会转发给指定的端口，所以，我们的访问就这样转发给了内网的服务器。服务器发送的数据包也通过这种途径转发给了外网的访问者，从而实现了外网访问内网的功能。 下面我们就具体谈一谈如何快速部署frp服务。 细节参见github文档 网主机端（server）：首先，你需要有一台外网主机，比如VPS，这里的东西就不赘述了。 接着，我们通过ssh登陆主机，执行以下命令: 123wget --no-check-certificate https://raw.githubusercontent.com/clangcn/onekey-install-shell/master/frps/install-frps.sh -O ./install-frps.shchmod 700 ./install-frps.sh./install-frps.sh install 然后按要求填写参数 1234567891011121314151617181920212223242526272829Loading network version for frps, please wait...frps Latest release file frp_0.8.1_linux_amd64.tar.gz #此步骤会自动获取frp最新版本，自动操作，无需理会Loading You Server IP, please wait...You Server IP:12.12.12.12 #自动获取你服务器的IP地 Please input your server setting:Please input frps bind_port [1-65535](Default Server Port: 5443): #输入frp提供服务的端口，用于服务器端和客户端通信Please input frps dashboard_port [1-65535](Default dashboard_port: 6443): #输入frp的控制台服务端口，用于查看frp工作状态Please input frps vhost_http_port [1-65535](Default vhost_http_port: 80): #输入frp进行http穿透的http服务端口Please input frps vhost_https_port [1-65535](Default vhost_https_port: 443): #输入frp进行https穿透的https服务端口Please input privilege_token (Default: WEWLRgwRjIJVPx2kuqzkGnvuftPLQniq): #输入frp服务器和客户端通信的密码，默认是随机生成的Please input frps max_pool_count [1-200](Default max_pool_count: 50): #设置每个代理可以创建的连接池上限，默认50Please select log_level #####1: info2: warn3: error4: debug############################Enter your choice (1, 2, 3, 4 or exit. default [1]):#设置日志等级，4个选项，默认是infoPlease input frps log_max_days [1-30](Default log_max_days: 3 day):#设置日志保留天数，范围是1到30天，默认保留3天。##### Please select log_file #####1: enable2: disable#####################################################Enter your choice (1, 2 or exit. default [1]):#设置是否开启日志记录，默认开启，开启后日志等级及保留天数生效，否则等级和保留天数无效 设置完成后检查你的输入，如果没有问题按任意键继续安装 123456789101112============== Check your input ==============You Server IP : 12.12.12.12Bind port : 5443Dashboard port : 6443vhost http port : 80vhost https port: 443Privilege token : WEWLRgwRjIJVPx2kuqzkGnvuftPLQniqMax Pool count : 50Log level : infoLog max days : 3Log file : enable============================================== 安装结束后显示： 1234567891011121314151617Congratulations, frps install completed!==============================================You Server IP : 12.12.12.12Bind port : 5443Dashboard port : 6443vhost http port : 80vhost https port: 443Privilege token : WEWLRgwRjIJVPx2kuqzkGnvuftPLQniqMax Pool count : 50Log level : infoLog max days : 3Log file : enable # 将上面信息添加到你的frp客户端中吧==============================================frps Dashboard: http://12.12.12.12:6443/ # 这个是frp控制台访问地址============================================== 这里补充几条这个脚本的命令： 更新命令: ./install-frps.sh update 卸载命令: ./install-frps.sh uninstall 服务器端管理命令: 1frps &#123;start|stop|restart|status|config|version&#125; Dashboard： 通过浏览器查看 frp 的状态以及代理统计信息展示。打开浏览器通过 http://[server_addr]:6443 访问 dashboard 界面，用户名密码默认为 admin。 dashboard 内网服务器端（client）：我们进入这个网页：https://github.com/fatedier/frp/releases 找到适合我们服务器的安装包，下载到服务器中，假设我们下载amd64版的到了/home文件夹中 执行命令cd /home 进入文件夹中，然后执行命令 tar -zxvf frp_0.14.0_linux_amd64.tar.gz进行解压 接着进入解压后的目录中cd frp_0.14.0_linux_amd64 然后开始修改配置文件vim frpc.ini 123456789101112131415161718192021[common]server_addr = x.x.x.x#填frp服务端的ip（也就是外网主机的IP）server_port = 5443#填frp服务端的frp提供服务的端口privilege_token = WEWLRgwRjIJVPx2kuqzkGnvuftPLQniq#填 frp服务器和客户端通信的密码tcp_mux = 50 #与外网主机中“每个代理可以创建的连接池上限，默认50”项相同[ssh]type = tcplocal_ip = 127.0.0.1local_port = 22remote_port = 6000#remote_port`就是通过外网访问内网服务器ssh服务时的端口。[web]type = httplocal_port = 80 #内网服务器http服务的端口custom_domains = leanote.njunova.com #指向外网主机的域名 官方的完整配置文件：https://github.com/fatedier/frp/blob/master/conf/frpc_full.ini 保存配置文件，执行命令 ./frpc -c ./frpc.ini启动frpc 后台运行和自启动使用nohup指令后台运行 nohup指令的使用方法相对简单，只需要在nohup后面加上frp的运行指令即可。下面示范的指令是运行frp客户端。 1nohup ./frpc -c ./frpc.ini &amp; 这样就成功让frp在后台运行了。 添加开机自启动 由于服务端（外网主机端）使用了脚本安装，已经自动开启了自启动，所以我们只需要设置客户端（内网服务器）的开启自启。 比如你的frp目录在/home/frp 那么执行命令nano /etc/rc.local编辑自启动文件 在里面的 exit 0前一行加入 sudo nohup /home/frp/frpc -c /home/frp/frpc.ini &amp;就可以啦！ 参考链接： 文章原地址 Github地址","tags":[{"name":"Linux","slug":"Linux","permalink":"https://geniuslight.github.io/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"https://geniuslight.github.io/tags/运维/"}]},{"title":"遥感中几类处理数据的概念整理","date":"2018-01-13T13:07:08.000Z","path":"2018/01/13/ImportantConceptInRemoteSensing/","text":"关于remote sensing（遥感）的一些概念整理，和其与深度学习发展的关系，阅读论文后对一些概念的整理。 处理数据有： 高光谱图像 孔径雷达图像 高分辨率卫星图像 英文摘要来自：Deep Learning in Remote Sensing: A Comprehensive Review and list of resources HYPERSPECTRAL IMAGE（高光谱图像）介绍： 高光谱影像(hyperspectral imaging)是收集及处理整个跨电磁波谱的信息。不像是人类的眼睛，只能接触到可见光。而高光谱的接触机制、比如虾蛄的眼睛它的光谱能够接触到红外线延伸到紫外线的范围。高光谱的能力能够使虾蛄分辨出不同的珊瑚、猎物，或则猎食者，而这些正是人类所缺少的。 工程师们已经制造出可用于农业、矿业、物理以及监控领域的传感器及处理系统。高光谱传感器通过大量的不同波段的电磁频谱来探测物体。实际物体会在电磁频谱中留下具有唯一的“指纹”。这些“指纹”被称为光谱特性并可用来确认被识别物体的组成成分。比如说，石油的光谱特性便可以用来帮助矿质学家们找到油田。 优点： 光谱分辨率高、波段众多，能够获取地物几乎连续的光谱特征曲线，并可以根据需要选择或提取特定波段来突出目标特征 同一空间分辨率下，光谱覆盖范围更宽，能够探测到地物更多对电磁波的响应特征 波段多，为波段之间的相互校正提供了便利 定量化的连续光谱曲线数据为地物光谱机理模型引入图像分类提供了条件 包含丰富的辐射、空间和光谱信息，是多种信息的综合载体 缺点： 数据量大，图像包含几十个到上百个波段，数据量是单波段遥感图像的几百倍；数据存在大量冗余，处理不当，反而会影响分类精度 对高光谱图像的分类一方面要求更高的光谱定标和反射率转换的精度，另一方面又因为成像机理复杂，数据量巨大而导致对图像数据预处理困难，包括大气矫正、几何校正、光谱定标和反射率转换等 波段多、波段间的相关性高，因此分类需要的训练样本数目大大增多，往往因训练样本不足导致得到的训练参数不可靠(维数灾难) 针对常规遥感的处理模型和方法不能满足高光谱图像分类的需求。主要问题之一是统计学分类模型的参数估计问题，其对光谱特征的选择要求很高 相关发展： Hyperspectral sensors are characterized by hundreds of narrow spectralbands. This very high spectral resolution enables us to identify the materialscontained in the pixel via spectroscopic analysis. Analysis of hyperspectral data is of great importance in many practical applications, such as landcover/use classification or change and object detection. Because high-qualityhyperspectral satellite data are becoming available (e.g., via the launch ofEnMAP, planned for 2020, and the DESIS on the International Space Station, planned for 2018), hyperspectral image analysis has been one of the most active research areas within the remote-sensing community over the last decade. Inspired by the success of deep learning in computer vision, preliminary studies have been carried out on deep learning in hyperspectral data analysis, which brings new momentum to this field. 相关任务： HYPERSPECTRAL IMAGE CLASSIFICATION SAE FOR HYPERSPECTRAL DATA CLASSIFICATION ANOMALY DETECTION SYNTHETIC APERTURE RADAR IMAGES（合成孔径雷达图像）介绍： 合成孔径雷达（英语：synthetic aperture radar, SAR），又译成合成口径雷达，属于一种微波成像雷达，也是一种可以产生高分辨率图像的（航空）机载雷达或（太空）星载雷达。它在早期系使用透镜成像机制在底片（胶卷）上形成影像，目前则以复杂的雷达数据后处理方法来获得极窄的有效辐射波束（对产生的雷达图像意味着极高的空间分辨率）。它一般安装在移动的载体上对相对静止的目标成像，或反之。自合成孔径雷达发明以来，它被广泛的应用于遥感和地图测绘。 优点： All-day，全天24小时可以工作 All-weather，不受大雾或者云层影响 具有一定的穿透能力，比如穿透树木和建筑物 缺点： 精度不高，噪点较多 个别时候有可能收到电磁干扰 会受到大气和土壤湿度的影响，冰雪覆盖也有影响 相关发展： Over the past several years, many studies related to deep learning for SAR image analysis have been published. Among these, deep learning techniques have been used most in typical applications, including automatic target recognition (ATR), terrain surface classification, and parameter inversion. 相关任务： AUTOMATIC TARGET RECOGNITION TERRAIN SURFACE CLASSIFICATION HIGH-RESOLUTION SATELLITE IMAGES （高分辨率图像）没有找到确切的定义，不过顾名思义，应该是分辨率很高的卫星，在查阅过程中分辨率在0.41m-2.36m的应该都算高分辨率卫星。 相关任务： SCENE CLASSIFICATION OBJECT DETECTION IMAGE RETRIEVAL 延伸阅读： 遥感影像有什么缺点 高光谱遥感图像相关知识梳理大全","tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://geniuslight.github.io/tags/深度学习/"},{"name":"遥感","slug":"遥感","permalink":"https://geniuslight.github.io/tags/遥感/"}]},{"title":"RGB-D数据库介绍","date":"2018-01-11T02:06:01.000Z","path":"2018/01/11/RGB-DDatasetIntro/","text":"RGB图像和深度图像的数据库简介，简单介绍在论文中看到的数据库特点、使用的任务！ SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite 10,335 RGB-D 图像 146,617个二维多边形和58,657个具有精确的物体方向的三维边界框，以及三维空间布局和场景类别 可使用任务：Scene Classification(场景理解)，Semantic Segmentation(语义分割)，3D Object detection (3D物体检测)，Object Orientation(物体定位)，Room Layout Estimation(房间布局估计)，Total Scene Understanding(场景理解) 链接：http://rgbd.cs.princeton.edu/ RGB-D (Kinect) Object Dataset-Washington 分为两部分：物体数据库和场景数据库。 1.物体数据库 41,877 RGB-D图像 300种物体，51类 可使用任务：物体分类 2.场景数据库（这部分没有深入了解） 14个场景，包括家具（椅子，咖啡，桌子， 沙发），和物体数据库中的一个子集，包括（碗， 杯子， 麦片盒， 咖啡马克杯， 汽水罐）。ps.不知道场景和物体有什么联系 3D点云图，相机相对每个场景位置，场景中包含物体的标记 可使用任务：Detection-based Object Labeling in 3D Scenes(物体检测) 链接：https://rgbd-dataset.cs.washington.edu/index.html 一个图像数据库的汇总，1019个链接，可以说非常强大了 链接：http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm#action","tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://geniuslight.github.io/tags/深度学习/"}]},{"title":"建站记录","date":"2017-12-20T11:42:49.000Z","path":"2017/12/20/Start/","text":"初衷记录成长的点点滴滴，给自己更多的思考时间！","tags":[{"name":"随笔","slug":"随笔","permalink":"https://geniuslight.github.io/tags/随笔/"}]},{"title":"Linux系统换源","date":"2017-12-20T08:19:34.000Z","path":"2017/12/20/LinuxChangeSource/","text":"Linux系统换源[TOC] linux界两大主流：RPM和DPKGLinux 开发商先在固定的硬件平台与操作系统平台上面将需要安装或升级的软件编译好， 然后将这个软件的所有相关文件打包成为一个特殊格式的文件，在这个软件文件内还包含了预先侦测系统与相依软件的脚本， 并提供记载该软件提供的所有文件资讯等。最终将这个软件文件释出。用户端取得这个文件后，只要透过特定的命令来安装， 那么该软件文件就会依照内部的脚本来侦测相依的前驱软件是否存在，若安装的环境符合需求，那就会开始安装， 安装完成后还会将该软件的资讯写入软件管理机制中，以达成未来可以进行升级、移除等动作。 目前在 Linux 界软件安装方式最常见的有两种，分别是： DPKG：这个机制最早是由 Debian Linux 社群所开发出来的，透过 dpkg 的机制， Debian 提供的软件就能够简单的安装起来，同时还能提供安装后的软件资讯，实在非常不错。 只要是衍生於 Debian 的其他 Linux distributions 大多使用 dpkg 这个机制来管理软件的， 包括 B2D, Ubuntu 等等。 RPM：这个机制最早是由 Red Hat 这家公司开发出来的，后来实在很好用，因此很多 distributions 就使用这个机制来作为软件安装的管理方式。包括 Fedora, CentOS, SuSE 等等知名的开发商都是用这。 目前新的 Linux 开发商都有提供『线上升级』机制，透过这个机制， 原版光盘就只有第一次安装时需要用到而已，其他时候只要有网络，你就能够取得原本开发商所提供的任何软件了呢！ 在 dpkg 管理机制上就开发出 APT 的线上升级机制，RPM 则依开发商的不同，有 Red Hat 系统的 yum ， SuSE 系统的 Yast Online Update (YOU)。 distribution 代表 软件管理机制 使用命令 线上升级机制(命令) Red Hat/Fedora RPM rpm, rpmbuild YUM (yum) Debian/Ubuntu DPKG dpkg APT (apt-get) Linux换源因为在线安装需要在服务器上下载需要软件和依赖关系文件，所以下载的速度很影响使用体验。一般来说，Linux默认的源安装和更新速度很慢，所以安装好系统一般会选择换源。 个人常用的源： 清华源 163源 举例在Ubuntu16.04和Centos7上如何换源 在Ubuntu上更换清华源：Ubuntu 16.04的软件源配置文件是 /etc/apt/sources.list。将系统自带的该文件做个备份，将该文件替换为下面内容，即可使用 TUNA 的软件源镜像。(其他版本sourcelist 参看 网页) 先备份在编辑 12mv /etc/apt/sources.list /etc/apt/sources.list.bakupsudo vim /etc/apt/sources.list 12345678910111213# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse# 预发布软件源，不建议启用# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse 访问源列表里的每个网址，并读取软件列表，然后保存在本地电脑。使用update命令更新。 1sudo apt-get update 在Centos上更换163源Centos7的源文件是/etc/yum.repos.d/CentOS-Base.repo。同理先备份，然后再替换文件即可。 首先备份 1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 再下载Centos，并且将其改成默认源文件。 12wget http://mirrors.163.com/.help/CentOS7-Base-163.repomv CentOS7-Base-163.repo /etc/yum.repos.d/CentOS-Base.repo 运行命令生成缓存 12yum clean allyum makecache 关于update和upgrade在Ubuntu下 sudo apt-get update 这个命令，会访问源列表里的每个网址，并读取软件列表，然后保存在本地电脑。我们在新立得软件包管理器里看到的软件列表，都是通过update命令更新的。 sudo apt-get upgrade 这个命令，会把本地已安装的软件，与刚下载的软件列表里对应软件进行对比，如果发现已安装的软件版本太低，就会提示你更新。如果源里面有系统更新，直接给你把系统升级。有网友表示会导致原来软件无法使用。 在Centos下 yum makecache 等同于 sudo apt-get update yum -y update 升级所有包，改变软件设置和系统设置,系统版本内核都升级。 yum -y upgrade 升级所有包，不改变软件设置和系统设置，系统版本升级，内核不改变。 参考： 鸟哥的Linux私房菜 ubuntu sudo update与upgrade的作用及区别","tags":[{"name":"Linux","slug":"Linux","permalink":"https://geniuslight.github.io/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"https://geniuslight.github.io/tags/运维/"}]},{"title":"登陆远程服务器桌面","date":"2017-12-20T08:19:34.000Z","path":"2017/12/20/RemoteAcessServer/","text":"解决方案 序号 方案 简单区别 方案一 Xmanager 1.VNC连接时及时突然中断（比如断网），不影响操作进行；2.不需要在服务器上装软件，需要在你的电脑上装相应软件，使用SSH协议；3.正版要钱 方案二 VNC(Virtual Network Computing) 1.本地操作突然中断，服务器端操作也中断；2.在服务器端装vncserver（有很多版本选择）,你的电脑装vncviewer客户端(有很多软件选择)；3.不要钱 VCN安装和配置vncserver和vncviewr选择有很多，我选择采用vnc4server + VNC Viewer 在服务器安装操作系统：Ubuntu16.04 Desktop 选择安装桌面和修改vnc相应配置，个人尝试安装了gnome和xface4 1.安装gnome 执行apt-get install vnc4server，安装vnc server 执行vncserver，按照提示设置VNC访问时的密码 执行apt-get install gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal，安装gnome窗口管理器 需要修改.vnc/xstartup配置文件。修改为下面的样子： 123456789101112#!/bin/shexportXKL_XMODMAP_DISABLE=1unsetSESSION_MANAGERunsetDBUS_SESSION_BUS_ADDRESSgnome-panel &amp;gnome-settings-daemon &amp;metacity &amp;nautilus &amp;gnome-terminal &amp;vncconfig &amp; 执行apt-get install vnc4server，安装vnc server 执行vncserver -geometry 1920×1080 :1，再次启动vnc server，其中1920X1080是屏幕分辨率，可自行修改 远程运行vnc的客户端（如：VNC Viewer）: IP地址+VNC端口（如：192.168.1.188：1） 关闭服务器端vncserver命令为vncserver -kill :i（i为你需要关闭的vnc端口） 2.安装xfce4 执行apt-get install vnc4server，安装vnc server 执行vncserver，按照提示设置VNC访问时的密码 执行sudo apt-get install xfce4，安装xfce4桌面环境 需要修改.vnc/xstartup配置文件。修改为下面的样子： 123456789101112131415#!/bin/sh# Uncomment the following two lines for normal desktop:# unset SESSION_MANAGER# exec /etc/X11/xinit/xinitrc[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresourcesxsetroot -solid greyvncconfig -iconic &amp;x-terminal-emulator -geometry 80x24+10+10 -ls -title \"$VNCDESKTOP Desktop\" &amp;#x-window-manager &amp;sesion-manager &amp; xfdesktop &amp; xfce4-panel &amp;xfce4-menu-plugin &amp;xfsettingsd &amp;xfconfd &amp;xfwm4 &amp; 执行sudo update-alternatives --config x-terminal-emulator，选择“/usr/bin/xterm”项或者“/usr/bin/xfce4-terminal.wrapper”，配置模拟终端,否则登录后无法启动终端 执行vncserver -geometry 1920×1080 :1，再次启动vnc server，其中1920X1080是屏幕分辨率，可自行修改 远程运行vnc的客户端（如：VNC Viewer）: IP地址+VNC端口（如：192.168.1.188：1） 效果如下： 这里写图片描述 遇到问题1安装gnome系统崩溃，再次登陆表现为：菜单无法显示，终端无法打开，新开用户可以重新打开终端，但是菜单任无法显示，所以采用xfce桌面。网上称vnc4server对gnome桌面支持有bug。 推荐直接使用安装xfce4并且修改相应配置 2 安装xfce后无法使用tab键在终端中自动补齐，原因是快捷键冲突。 解决方法： 菜单栏 → 设置 → 窗口设置 。打开窗口设置对话框 在窗口管理器中选择快捷键选项卡（Key） → Switch window for same application 将冲突快捷键清空，关闭窗口管理器 参考： 在ubuntu16.04.1-desktop(amd64)上设置VNC ubuntu16.04 vncserver配置 在VNC中Xfce4中Tab键失效的解决方法 ​","tags":[{"name":"Linux","slug":"Linux","permalink":"https://geniuslight.github.io/tags/Linux/"},{"name":"运维","slug":"运维","permalink":"https://geniuslight.github.io/tags/运维/"}]}]